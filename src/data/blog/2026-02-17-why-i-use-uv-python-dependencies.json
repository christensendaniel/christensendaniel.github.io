{
  "id": "2026-02-17-why-i-use-uv-python-dependencies",
  "title": "Why I Use uv for Python Dependency Management",
  "author": "Daniel Christensen",
  "date": "February 17, 2026",
  "dateISO": "2026-02-17",
  "description": "How uv simplified my Python workflow for creating reproducible environments and managing dependencies in data pipelines and AI projects.",
  "tags": ["Python", "uv", "DevOps", "Dependencies", "Tools"],
  "excerpt": "How uv simplified my Python workflow for creating reproducible environments and managing dependencies in data pipelines and AI projects.",
  "content": "<p>Python dependency management has too many solutions. pip, pip-tools, poetry, pipenv, conda, hatch — each with different trade-offs and learning curves. For most of my work, I've settled on <a href=\"https://github.com/astral-sh/uv\" target=\"_blank\" rel=\"noopener noreferrer\">uv</a>.</p><h2 id=\"what-uv-does-well\">What uv Does Well</h2><p>I use uv primarily for two things: creating virtual environments and managing package dependencies. It does both fast and with minimal configuration.</p><p>Creating an environment and installing dependencies:</p><pre><code>uv venv\nsource .venv/bin/activate  # or .venv\\Scripts\\activate on Windows\nuv pip install -r requirements.txt</code></pre><p>That's it. No ceremony. No complex configuration files to maintain.</p><h2 id=\"where-it-fits\">Where It Fits in My Workflow</h2><p>For data pipelines and AI projects — where I'm building applications rather than distributable packages — uv is my default. It creates reproducible environments quickly and makes dependency updates straightforward.</p><p>For building Python packages intended for PyPI, I still use Hatch. Hatch's <code>pyproject.toml</code> integration and build backend are better suited for packaging. But for everything else — ETL scripts, LLM integrations, ML training pipelines — uv handles it.</p><h2 id=\"pyproject-toml\">Using pyproject.toml Instead of Requirements Files</h2><p>I've moved away from bare <code>requirements.txt</code> files to using <code>pyproject.toml</code> for dependency management. This provides better structure and follows modern Python packaging standards.</p><p>Here's a typical <code>pyproject.toml</code> I use:</p><pre><code>[project]\nname = \"my-project\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.11\"\ndependencies = [\n    \"transformers&gt;=4.35.0\",\n    \"langchain&gt;=0.1.0\",\n    \"openai&gt;=1.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.0.0\",\n    \"black&gt;=23.0.0\",\n    \"ruff&gt;=0.1.0\",\n]\ntest = [\n    \"pytest&gt;=7.0.0\",\n    \"pytest-cov&gt;=4.0.0\",\n]</code></pre><p>Then install with:</p><pre><code># Production dependencies\nuv pip install -e .\n\n# Development dependencies\nuv pip install -e \".[dev]\"\n\n# Testing dependencies\nuv pip install -e \".[test]\"</code></pre><p>See my actual <code>pyproject.toml</code> configurations in my <a href=\"https://github.com/christensendaniel\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub repositories</a>.</p><h2 id=\"reproducibility\">Reproducibility and Updates</h2><p>uv generates lock files that pin exact versions, making environments reproducible across machines and deployments. When combined with <a href=\"/blog/2026-02-13-dependabot-ai-code-security-github-actions\">Dependabot for automated security updates</a>, it creates a workflow that balances stability with staying current on patches.</p><p>The <code>pyproject.toml</code> approach means you declare broad version ranges in your project configuration:</p><pre><code>dependencies = [\n    \"transformers&gt;=4.35.0\",\n    \"langchain&gt;=0.1.0\",\n    \"openai&gt;=1.0.0\",\n]</code></pre><p>Then resolve to specific versions with a lock file. You get flexibility in development and precision in production.</p><h2 id=\"different-contexts\">Different Requirements for Different Contexts</h2><p>Real projects have different dependency needs depending on context:</p><ul><li><strong>Development</strong>: testing tools, linters, formatters</li><li><strong>Testing</strong>: test frameworks, coverage tools</li><li><strong>Production</strong>: minimal runtime dependencies only</li></ul><p>Using <code>pyproject.toml</code> makes this straightforward with optional dependencies:</p><pre><code># Development\nuv pip install -e \".[dev]\"\n\n# Testing (CI/CD)\nuv pip install -e \".[test]\"\n\n# Production (Docker)\nuv pip install -e .</code></pre><p>No extra dependencies in production. No missing tools in development.</p><h2 id=\"speed-matters\">Speed Matters</h2><p>uv is written in Rust and is noticeably faster than pip for most operations. Installing hundreds of packages in a fresh environment that takes pip 2-3 minutes completes in under 30 seconds with uv.</p><p>When you're iterating on a pipeline or debugging environment issues, that difference compounds.</p><h2 id=\"why-i-use-it\">Why I Actually Use It</h2><p>I don't use uv because it's theoretically better (though everything in Rust <em>is</em> better, right?).</p><p>I use it because it handles the workflows I actually have: creating environments quickly, managing dependencies cleanly, and keeping production lean.</p><p>For package development, Hatch is still the right tool as far as I can see. But for everything else — data engineering, AI projects, automation scripts — uv is faster, simpler, and sufficient.</p><p>Learn more about uv at <a href=\"https://astral.sh/uv\" target=\"_blank\" rel=\"noopener noreferrer\">astral.sh/uv</a>.</p><p>See example configurations and workflows in my <a href=\"https://github.com/christensendaniel\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub repositories</a>.</p>"
}
